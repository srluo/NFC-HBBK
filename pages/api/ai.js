// /pages/api/ai.js â€” v1.9.2ï¼ˆAI æ‘˜è¦è¼•é‡å„ªåŒ–ï¼‰
// ------------------------------------------------------------
// âœ… é‡é»æ›´æ–°ï¼š
// 1ï¸âƒ£ å­—æ•¸æ§åˆ¶ï¼šé™åˆ¶ 120â€“150 å­—ã€‚
// 2ï¸âƒ£ ç¦æ­¢é‡è¤‡æåŠæ˜Ÿåº§ï¼ç”Ÿè‚–åç¨±ï¼ˆæ¸›å°‘å†—èªï¼‰ã€‚
// 3ï¸âƒ£ ä¿ç•™å››æ®µçµæ§‹ï¼ˆæ•´é«”ã€å„ªé»ã€æ³¨æ„ã€é¼“å‹µï¼‰ï¼Œä½†èªæ°£æ›´ç²¾ç°¡ã€‚
// ------------------------------------------------------------

import OpenAI from "openai";
const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export default async function handler(req, res) {
  try {
    if (req.method !== "POST")
      return res.status(405).json({ error: "Method Not Allowed" });

    const {
      name,
      gender,
      zodiac,
      constellation,
      blood_type,
      bureau,
      ming_lord,
      shen_lord,
      ming_stars,
    } = req.body || {};

    if (!name || !constellation || !zodiac)
      return res.status(400).json({ error: "ç¼ºå°‘å¿…è¦åƒæ•¸" });

    // ğŸ¯ Promptï¼ˆ120â€“150 å­—å…§ï¼‰
    const prompt = `
ä½ æ˜¯ä¸€ä½äººæ ¼å¿ƒç†é¡§å•ï¼Œæ ¹æ“šä»¥ä¸‹è³‡æ–™æ’°å¯«ä¸€æ®µç´„ 120â€“150 å­—çš„ã€Œå€‹æ€§æ‘˜è¦ã€ï¼š
---
å§“åï¼š${name}
æ€§åˆ¥ï¼š${gender || "æœªæŒ‡å®š"}
ç”Ÿè‚–ï¼š${zodiac}
æ˜Ÿåº§ï¼š${constellation}
è¡€å‹ï¼š${blood_type || "æœªå¡«"}
äº”è¡Œå±€ï¼š${bureau || "æœªçŸ¥"}
å‘½ä¸»æ˜Ÿï¼š${ming_lord || "æœªçŸ¥"}
èº«ä¸»æ˜Ÿï¼š${shen_lord || "æœªçŸ¥"}
å‘½å®®ä¸»æ˜Ÿç¾¤ï¼š${Array.isArray(ming_stars) ? ming_stars.join("ã€") : ming_stars || "ç„¡"}
---
è¦æ±‚ï¼š
1ï¸âƒ£ ä¸è¦é‡è¤‡æåŠæ˜Ÿåº§ã€ç”Ÿè‚–åç¨±ã€‚
2ï¸âƒ£ ä»¥æº«æš–ã€è‡ªç„¶ã€å…·æ´å¯ŸåŠ›çš„èªæ°£æ’°å¯«ã€‚
3ï¸âƒ£ åˆ†ç‚ºä¸‰æ®µï¼šæ•´é«”æ€§æ ¼ã€æ½›èƒ½èˆ‡å„ªé»ã€éœ€æ³¨æ„ç¼ºé»èˆ‡é¼“å‹µã€‚
4ï¸âƒ£ æ¯æ®µé–“è«‹åŠ ä¸€å€‹ç©ºè¡Œï¼ˆ\\n\\nï¼‰ã€‚
5ï¸âƒ£ å­—æ•¸è«‹æ§åˆ¶åœ¨ 120ï½150 å­—å…§ã€‚
`;

    const completion = await client.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content:
            "ä½ æ˜¯ä¸€ä½èåˆå¿ƒç†å­¸èˆ‡å‘½ç†è§€å¯Ÿçš„é¡§å•ï¼Œæ“…é•·ç”¨ç°¡æ½”ã€èª æ‡‡ã€æ­£é¢çš„èªæ°£æ’°å¯«å€‹äººåŒ–æ‘˜è¦ã€‚",
        },
        { role: "user", content: prompt },
      ],
      temperature: 0.8,
      max_tokens: 220, // æ§åˆ¶ç”Ÿæˆä¸Šé™
    });

    const summary = completion.choices?.[0]?.message?.content?.trim() || "";

    return res.json({ ok: true, summary });
  } catch (e) {
    console.error("ai.js error:", e);
    return res.status(500).json({ error: "AI ç”Ÿæˆå¤±æ•—" });
  }
}
